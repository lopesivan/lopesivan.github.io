<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Welcome to Ivan Lopes's Homepage</title>
    <description>Todos os meus textos e trabalhos sempre estiveram confinados a academia e ao mercado de trabalho, sendo assim, resolvi criar este blog para compartilhar estes trabalho e  discutir tópicos relacionados a engenharia elétrica e ciências correlatas.
</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 13 Dec 2019 23:57:27 -0300</pubDate>
    <lastBuildDate>Fri, 13 Dec 2019 23:57:27 -0300</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>Welcome to Jekyll!</title>
        <description>&lt;p&gt;You’ll find this post in your &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;p&gt;To add new posts, simply add a file in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory that follows the convention &lt;code class=&quot;highlighter-rouge&quot;&gt;YYYY-MM-DD-name-of-post.ext&lt;/code&gt; and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.&lt;/p&gt;

&lt;p&gt;Ivan Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Tom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints 'Hi, Tom' to STDOUT.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Check out the &lt;a href=&quot;http://jekyllrb.com/docs/home&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll’s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Fri, 13 Dec 2019 17:15:23 -0300</pubDate>
        <link>http://localhost:4000/jekyll/update/2019/12/13/welcome-to-jekyll.html</link>
        <guid isPermaLink="true">http://localhost:4000/jekyll/update/2019/12/13/welcome-to-jekyll.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Estado da arte e tendências na era do  Aprendizado profundo</title>
        <description>&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;A reconstrução 3D é um problema antigo e mal colocado, que tem sido explorado
há décadas pela visão computacional,computação gráfica e comunidades de
aprendizado de máquina. Desde 2015, a reconstrução 3D com base em imagem
usando sistemas neurais convolucionaisredes (CNN) atraiu um interesse
crescente e demonstrou um desempenho impressionante. Dada esta nova era de
rápida evolução, este artigo fornece uma pesquisa abrangente dos
desenvolvimentos recentes nesse campo. Focamos nos trabalhos que usam
aprendizado profundo técnicas para estimar a forma 3D de objetos genéricos a
partir de uma única ou várias imagens RGB. Organizamos a literatura com base
nas representações de forma, nas arquiteturas de rede e nos mecanismos de
treinamento que eles usam. Embora esta pesquisa se destine a métodos que
reconstroem objetos genéricos, também revisamos alguns dos trabalhos recentes
que se concentram em classes de objetos específicas, como formas e rostos do
corpo humano. Fornecemos uma análise e comparação do desempenho de alguns
documentos principais, resumimos alguns dos problemas em aberto nesse campo e
discutir direções promissoras para pesquisas futuras.&lt;/p&gt;

&lt;h1 id=&quot;introdução&quot;&gt;INTRODUÇÃO&lt;/h1&gt;

&lt;p&gt;objetivo da reconstrução 3D baseada em imagem é inferir a geometria e estrutura
de objetos e cenas de um ou várias imagens 2D. Este problema de longa data mal
posicionado é fundamental para muitas aplicações, como navegação por
robô, reconhecimento de objetos e compreensão de cenas, modelagem 3D e animação,
controle industrial e diagnóstico médico.&lt;/p&gt;

&lt;p&gt;A recuperação da dimensão perdida a partir de apenas imagens 2D foi o objetivo
do estéreo multivista clássico e do formato Métodos X, que foram
extensivamente investigados por muitas décadas.  A primeira geração de métodos
abordava o problema da perspectiva geométrica; eles focaram na compreensão e
formalização, matematicamente, do 3D ao processo de projeção 2D, com o objetivo
de elaborar soluções técnicas ou algorítmicas para a inversa mal postalem.&lt;/p&gt;

&lt;p&gt;Soluções eficazes geralmente exigem várias imagens, capturado usando câmeras
calibradas com precisão. Baseado em estéreo técnicas [ 1] , por exemplo, exigem
recursos correspondentes imagens capturadas de ângulos de visão ligeiramente
diferentes e use o princípio da triangulação para recuperar a coordenação
3D dinates dos pixels da imagem.  Forma a partir da silhueta ou forma pelo
espaço-escultura, métodos [ 2] requerem segmentação precisa Silhuetas 2D. Esses
métodos, que levaram a razões reconstruções 3D de qualidade aceitável, exigem
várias imagens de o mesmo objeto capturado por câmeras bem calibradas. Este,no
entanto, pode não ser prático ou viável em muitas situações.&lt;/p&gt;

&lt;p&gt;Curiosamente, os seres humanos são bons em resolver esses problemas problemas
inversos, aproveitando o conhecimento prévio. Eles podem inferir o tamanho
aproximado e a geometria aproximada dos objetos usando apenas um olho. Eles
podem até adivinhar o que seria parece de outro ponto de vista. Nós podemos
fazer isso porque todos os objetos e cenas vistos anteriormente nos
permitiram construir conhecimento prévio e desenvolver modelos mentais de como
são os objetos. A segunda geração de reconhecimento 3D métodos de construção
tentaram alavancar esse conhecimento prévio formular o problema de reconstrução
3D como reconhecimento problema. A avenida das técnicas de aprendizado profundo
e muito maisimportante, a crescente disponibilidade de grandes dados de
treinamento conjuntos, levaram a uma nova geração de métodos capazes
de recuperar a geometria 3D e a estrutura dos objetos de um ou múltiplas imagens
RGB sem a complexidade da câmera processo de separação. Apesar de recentes,
esses métodos têm demonstrou resultados emocionantes e promissores em
vários tarefas relacionadas à visão e gráficos de computador.&lt;/p&gt;

&lt;p&gt;Neste artigo, fornecemos uma estrutura abrangente e revisão detalhada dos
recentes avanços na reconstrução usando técnicas de aprendizagem profunda.
Primeiro focamos formas genéricas e, em seguida, discutir casos específicos,
como o corpo humano molda a face da reconstrução e a cena 3D análise.
Reunimos 149 trabalhos, que apareceram desde 2015 na liderança em visão
computacional, computação gráfica,e conferências e periódicos de aprendizado
de máquina1. O objetivoé ajudar o leitor a navegar neste campo emergente,
que ganhou um impulso significativo nos últimos anos. Comparados à literatura
existente, as principais contribuições deste artigo é o seguinte;&lt;/p&gt;

&lt;p&gt;1) Até onde sabemos, esta é a primeira pesquisa artigo na literatura que se
concentra na imagem reconstrução de objetos 3D baseada em aprendizagem
profunda.&lt;/p&gt;

&lt;p&gt;2) Cobrimos a literatura contemporânea com respeito para esta área.
Apresentamos uma revisão abrangente de 149 métodos, que surgiram desde 2015.&lt;/p&gt;

&lt;p&gt;3) Fornecemos uma análise abrangente e uma análise perspicaz de todos os
aspectos da reconstrução 3D usando aprendizado profundo, incluindo os dados de
treinamento, escolha das arquiteturas de rede e seus efeitos sobre os resultados
da reconstrução 3D, as estratégias de treinamento,e os cenários de
aplicativos.&lt;/p&gt;

&lt;p&gt;4) Fornecemos um resumo comparativo das propriedades e desempenho
dos métodos revisados para reconstrução genérica de objetos 3D. Cobrimos
88 algoritmos para reconstrução genérica de objetos 3D, 11 métodos relacionados
à reconstrução da face 3D e 6 métodos para reconstrução 3D da forma do corpo
humano.&lt;/p&gt;

&lt;p&gt;5) Fornecemos um resumo comparativo dos métodos de forma tabular.&lt;/p&gt;

&lt;p&gt;O restante deste artigo está organizado da seguinte forma; Seção 2 fo-detalha
o problema e estabelece a taxonomia. Seção 3analisa os espaços latentes e os
mecanismos de codificação de entradanismos. A Seção 4 examina as técnicas de
reconstrução volumétricatécnicas, enquanto a Seção 5 se concentra em técnicas
de superfície.A seção 6 mostra como algumas das técnicas de pontause dicas
adicionais para aumentar o desempenho da recuperação 3Dconstrução. A seção 7
discute os procedimentos de treinamento.A seção 8 concentra-se em objetos
específicos, como o corpo humanoformas e rostos. Seção 9 resume as mais
comunsconjuntos de dados usados ​​para treinar, testar e avaliar o
desempenho devários algoritmos de reconstrução 3D baseados em aprendizado
profundo.A Seção 10 compara e discute o desempenho de algumasprincipais
métodos. Por fim, a Seção 11 discute o potencial futuroinstruções de pesquisa
enquanto a Seção 12 conclui o artigocom algumas observações importantes.&lt;/p&gt;

&lt;figure class=&quot;panel-image&quot;&gt;
   &lt;a href=&quot;https://github.com/lopesivan/impa-2019-11-21/raw/master/1906.06543.pdf&quot;&gt;
   &lt;img src=&quot;imgs/pdf.png&quot; style=&quot;max-width: 100px;&quot; alt=&quot;Paper&quot; /&gt;
   &lt;/a&gt;
   &lt;figcaption&gt;Image-based 3D Object Reconstruction: State-of-the-Art and Trends in the Deep Learning Era.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure class=&quot;panel-image&quot;&gt;
   &lt;a href=&quot;https://github.com/lopesivan/impa-2019-11-21/raw/master/slide.pdf&quot;&gt;
   &lt;img src=&quot;imgs/pdf.png&quot; style=&quot;max-width: 100px;&quot; alt=&quot;Slide&quot; /&gt;
   &lt;/a&gt;
   &lt;figcaption&gt;Aprsentação&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;div&gt;
   Artigo usado na apresentação: &lt;a href=&quot;docs/1906.06543.pdf&quot;&gt;Image-based 3D Object Reconstruction: State-of-the-Art and Trends in the Deep Learning Era.&lt;/a&gt;
&lt;/div&gt;

&lt;div&gt;
   Slide baseado no artigo proposto: &lt;a href=&quot;docs/slide.pdf&quot;&gt;Reconstrução de objetos 3D baseados em imagem.&lt;/a&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;Ivan Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;p&gt;Ivan Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Tom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints 'Hi, Tom' to STDOUT.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Check out the &lt;a href=&quot;https://github.com/lopesivan/impa-2019-11-21/raw/master/slide.pdf&quot;&gt;Slide&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll’s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Thu, 21 Nov 2019 17:15:23 -0300</pubDate>
        <link>http://localhost:4000/paper/presentation/2019/11/21/image-processing-for-vision-and-graphics.html</link>
        <guid isPermaLink="true">http://localhost:4000/paper/presentation/2019/11/21/image-processing-for-vision-and-graphics.html</guid>
        
        
        <category>Paper</category>
        
        <category>Presentation</category>
        
      </item>
    
  </channel>
</rss>
