<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Welcome to Ivan Lopes's Homepage</title>
    <description>Todos os meus textos e trabalhos sempre estiveram confinados a academia e ao mercado de trabalho, sendo assim, resolvi criar este blog para compartilhar estes trabalho e  discutir tópicos relacionados a engenharia elétrica e ciências correlatas.
</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 14 Dec 2019 05:34:32 -0300</pubDate>
    <lastBuildDate>Sat, 14 Dec 2019 05:34:32 -0300</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>Welcome to Jekyll!</title>
        <description>&lt;p&gt;You’ll find this post in your &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;p&gt;To add new posts, simply add a file in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory that follows the convention &lt;code class=&quot;highlighter-rouge&quot;&gt;YYYY-MM-DD-name-of-post.ext&lt;/code&gt; and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.&lt;/p&gt;

&lt;p&gt;Ivan Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Tom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints 'Hi, Tom' to STDOUT.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Check out the &lt;a href=&quot;http://jekyllrb.com/docs/home&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll’s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Fri, 13 Dec 2019 17:15:23 -0300</pubDate>
        <link>http://localhost:4000/jekyll/update/2019/12/13/welcome-to-jekyll.html</link>
        <guid isPermaLink="true">http://localhost:4000/jekyll/update/2019/12/13/welcome-to-jekyll.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Estado da arte e tendências na era do  Aprendizado profundo</title>
        <description>&lt;div&gt;
   Artigo usado na apresentação: &lt;a href=&quot;docs/1906.06543.pdf&quot;&gt;Image-based 3D Object Reconstruction: State-of-the-Art and Trends in the Deep Learning Era.&lt;/a&gt;
&lt;/div&gt;

&lt;div&gt;
   Slide baseado no artigo proposto: &lt;a href=&quot;docs/slide.pdf&quot;&gt;Reconstrução de objetos 3D baseados em imagem.&lt;/a&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt;
&lt;!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt;
&lt;p&gt;&lt;strong&gt;Tabela de Conteúdo&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#abstract&quot;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#introdu%C3%A7%C3%A3o&quot;&gt;INTRODUÇÃO&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#a-evolu%C3%A7%C3%A3o-dos-m%C3%A9todos-de-reconstru%C3%A7%C3%A3o-3d&quot;&gt;A evolução dos métodos de reconstrução 3D&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#compara%C3%A7%C3%A3o-de-m%C3%A9todos-de-constru%C3%A7%C3%A3o&quot;&gt;Comparação de métodos de construção&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bibliografia&quot;&gt;Bibliografia&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#materiais-adicionais&quot;&gt;Materiais adicionais&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;A reconstrução 3D é um problema antigo e mal colocado, que tem
sido explorado há décadas pela visão computacional, computação
gráfica e comunidades de aprendizado de máquina. Desde 2015, a
reconstrução 3D com base em imagem usando sistemas neurais
convolucionaisredes (CNN) atraiu um interesse crescente e
demonstrou um desempenho impressionante. Dada esta nova era de
rápida evolução, este artigo fornece uma pesquisa abrangente dos
desenvolvimentos recentes nesse campo. Focando nos trabalhos que
usam aprendizado profundo e técnicas para estimar a forma 3D de
objetos genéricos a partir de uma única ou várias imagens RGB.&lt;/p&gt;

&lt;p&gt;Organizamos a literatura com base nas representações de forma,
nas arquiteturas de rede e nos mecanismos de treinamento que que
são usados. Embora esta pesquisa se destine a métodos que
reconstroem objetos genéricos, também é revisado alguns dos
trabalhos recentes que se concentram em classes de objetos
específicas, como formas e rostos humanos. É fornecido uma
análise e comparação do desempenho de alguns documentos
principais, resumindo-se alguns dos problemas em aberto nesse
campo e propondo direções promissoras para pesquisas futuras.&lt;/p&gt;

&lt;figure&gt;
   &lt;a href=&quot;/paper/presentation/2019/11/21/imgs/3d_bounding_box_estimation_using_deep_learning_and_geometry.png&quot;&gt;
   &lt;img src=&quot;imgs/3d_bounding_box_estimation_using_deep_learning_and_geometry.png&quot; style=&quot;max-width: 80%;&quot; alt=&quot;3d_bounding_box_estimation_using_deep_learning_and_geometry.png&quot; /&gt;
   &lt;/a&gt;
   &lt;figcaption&gt;Estimativa de caixas delimitadoras 3D usando aprendizado profundo e geometria&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;introdução&quot;&gt;INTRODUÇÃO&lt;/h2&gt;

&lt;p&gt;O objetivo da reconstrução 3D baseada em imagem é inferir a
geometria e estrutura de objetos e cenas partindo de um ou
várias imagens 2D. Este problema de longa data que é mal
posicionado é fundamental para muitas aplicações, como navegação
por robô, reconhecimento de objetos e compreensão de cenas,
modelagem 3D e animação, controle industrial e diagnóstico
médico.&lt;/p&gt;

&lt;p&gt;A recuperação da dimensão perdida a partir de apenas imagens 2D
foi o objetivo do estéreo multivista clássico e do formato
Métodos X, que foram extensivamente investigados por muitas
décadas.  A primeira geração de métodos abordava o problema da
perspectiva geométrica; eles focaram na compreensão e
formalização, matematicamente, do 3D ao processo de projeção 2D,
com o objetivo de elaborar soluções técnicas ou algorítmicas
para obtenção do mecanismo inverso.&lt;/p&gt;

&lt;h2 id=&quot;a-evolução-dos-métodos-de-reconstrução-3d&quot;&gt;A evolução dos métodos de reconstrução 3D&lt;/h2&gt;

&lt;p&gt;Soluções eficazes geralmente exigem várias imagens, capturadas a
partir de câmeras calibradas com precisão. Baseando-se em
técnicas de estéreo, por exemplo, exigem como recursos
correspondentes imagens capturadas de ângulos de visão
ligeiramente diferentes e que se use o princípio da triangulação
para recuperar a coordenação 3D diante dos pixels da imagem.&lt;/p&gt;

&lt;p&gt;Formam-se a partir da silhueta ou forma pelo espaço escultural,
métodos que requerem segmentação precisa das silhuetas 2D. Esses
métodos, que levaram a razões reconstruções 3D de qualidade
aceitável, exigem várias imagens de o mesmo objeto capturado por
câmeras bem calibradas. Este,no entanto, pode não ser prático ou
viável em muitas situações devido ao alto custo computacional.&lt;/p&gt;

&lt;p&gt;Curiosamente, os seres humanos são bons em resolver esses
problemas problemas inversos, aproveitando-se  de algum conhecimento
prévio. Eles podem inferir o tamanho aproximado e a geometria
aproximada dos objetos usando apenas um olho. Eles podem até
adivinhar o que seria partindo de outro ponto de vista. Nós
podemos fazer isso porque todos os objetos e cenas vistos
anteriormente nos permitiram construir conhecimento prévio e
desenvolver modelos mentais de como são os objetos.&lt;/p&gt;

&lt;p&gt;A segunda geração de métodos de construção 3D tentou
usar esse conhecimento prévio e reformular formular o problema de
reconstrução 3D com reconhecimento problema. O caminho das
técnicas de aprendizado profundo são muito mais importantes, pois
a crescente disponibilidade de grandes dados de treinamento em
conjunto, levar a uma nova geração de métodos capazes de
recuperar a geometria 3D e a estrutura dos objetos de um ou
múltiplas imagens RGB sem a complexidade da câmera e processo de
separação e filtragem. Apesar de recentes, esses métodos têm demonstrado
resultados emocionantes e promissores em várias tarefas
relacionadas à visão computacional e processamento de imagem.&lt;/p&gt;

&lt;figure&gt;
   &lt;a href=&quot;/paper/presentation/2019/11/21/imgs/a-square-net-min.jpg&quot;&gt;
   &lt;img src=&quot;imgs/a-square-net-min.jpg&quot; style=&quot;max-width: 80%;&quot; alt=&quot;a-square-net-min.jpg&quot; /&gt;
   &lt;/a&gt;
   &lt;figcaption&gt;Modelo avançado de predição de forma com múltiplas redes&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;comparação-de-métodos-de-construção&quot;&gt;Comparação de métodos de construção&lt;/h2&gt;

&lt;figure&gt;
   &lt;a href=&quot;/paper/presentation/2019/11/21/imgs/Core55.png&quot;&gt;
   &lt;img src=&quot;imgs/Core55.png&quot; style=&quot;max-width: 100%;&quot; alt=&quot;Core55.png&quot; /&gt;
   &lt;/a&gt;
   &lt;figcaption&gt;Estimativa e raqueamento de métodos de reconstrução 3D por modelo de rede&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;bibliografia&quot;&gt;Bibliografia&lt;/h2&gt;

&lt;p&gt;Uma vasta &lt;a href=&quot;https://raw.githubusercontent.com/lopesivan/impa-2019-11-21/master/referencias.bib&quot;&gt;bibliografia&lt;/a&gt; foi utilizada para
realização deste trabalho e assim sendo é necessário fazer duas
menções honrosas, sendo a primeira destinada ao pesquisador
&lt;a href=&quot;http://lvelho.impa.br&quot;&gt;Luiz Velho&lt;/a&gt; cujo profissionalismo e trabalho inspiram a
todos que iforam seus alunos ou leitores de seus seus livros e
textos, e a segunda menção é ao Lucuino da Fontoura Costa que no
trabalho &lt;em&gt;Gauss’ law in image processing and analysis via fast
numerical calculation of vector fields&lt;/em&gt; publicado em 1999
aprensentou estudos deterministicos de cálculo de campos
vetorias e predição de formas.&lt;/p&gt;

&lt;h2 id=&quot;materiais-adicionais&quot;&gt;Materiais adicionais&lt;/h2&gt;

&lt;p&gt;Abaixo, mais alguns links para download dos arquivos em formato
pdf da apresentação e do paper discutido.&lt;/p&gt;

&lt;figure&gt;
   &lt;a href=&quot;https://github.com/lopesivan/impa-2019-11-21/raw/master/1906.06543.pdf&quot;&gt;
   &lt;img src=&quot;imgs/pdf.png&quot; style=&quot;max-width: 100px;&quot; alt=&quot;Paper&quot; /&gt;
   &lt;/a&gt;
   &lt;figcaption&gt;Image-based 3D Object Reconstruction: State-of-the-Art and Trends in the Deep Learning Era.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
   &lt;a href=&quot;https://github.com/lopesivan/impa-2019-11-21/raw/master/slide.pdf&quot;&gt;
   &lt;img src=&quot;imgs/pdf.png&quot; style=&quot;max-width: 100px;&quot; alt=&quot;Slide&quot; /&gt;
   &lt;/a&gt;
   &lt;figcaption&gt;Apresentação&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;O código fonte da implementação estatística do problema das &lt;a href=&quot;https://raw.githubusercontent.com/lopesivan/impa-2019-11-21/master/code/classify_stairs_nnet_from_scratch.R&quot;&gt;classificação das escadas em tons de cinza&lt;/a&gt;
conforme mostrado no &lt;a href=&quot;https://github.com/lopesivan/impa-2019-11-21/raw/master/slide.pdf&quot;&gt;slide&lt;/a&gt; da apresentação.&lt;/p&gt;

&lt;!--
vim: set ts=4 sw=4 tw=64 ft=markdown:
--&gt;
</description>
        <pubDate>Thu, 21 Nov 2019 17:15:23 -0300</pubDate>
        <link>http://localhost:4000/paper/presentation/2019/11/21/image-processing-for-vision-and-graphics.html</link>
        <guid isPermaLink="true">http://localhost:4000/paper/presentation/2019/11/21/image-processing-for-vision-and-graphics.html</guid>
        
        
        <category>Paper</category>
        
        <category>Presentation</category>
        
      </item>
    
  </channel>
</rss>
